test_size: 100000
num_workers: 4
tokenizer_name: /leonardo_work/AIFAC_L01_028/ggala000/tokenizers/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e
pre_tokenize: false
sequence_packing: false
max_add_padding: 0
trust_remote_code: False
dataset_subset: null
cache_dir: /leonardo_scratch/large/userexternal/avettoru/.cache
